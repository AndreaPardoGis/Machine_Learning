{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1be366b-ce0c-4c52-b03c-f3ba32fed318",
   "metadata": {},
   "source": [
    "## Clasificación con Árboles de Decisión y Bosques Aleatorios\n",
    "\n",
    "En este proyecto, vamos a usar dos técnicas de aprendizaje automático: \n",
    "\n",
    "    1. Árboles de Decisión\n",
    "    2. Bosques Aleatorios\n",
    "    \n",
    "Vamos a usar estos modelos para clasificar datos, evaluar su rendimiento y analizar la importancia de las características en el dataset de Iris.\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "    - Implementar y ajustar modelos de Árboles de Decisión y Bosques Aleatorios utilizando 'scikit-learn'.\n",
    "    - Visualizar y comprender la estructura de los Árboles de Decisión.\n",
    "    - Evaluar el rendimiento de los modelos mediante métricas como la matriz de confusión y el informe de clasificación.\n",
    "    - Analizar la importancia de las características par cada modelo.\n",
    "    - Comparar el desempeño de los modelos en términos de precisión y generalización."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf548c1e-e9e7-41ce-b84f-8b0c7008fe81",
   "metadata": {},
   "source": [
    "### 1. Importar las librerías y cargar los datos\n",
    "\n",
    "Importamos librerias necesarias para la manipulacion de datos (numpy, pandas), para la visualización (matplotlib, seaborn) y para machine learning (scikit-learn).\n",
    "\n",
    "Luego cargamos el dataset de flores iris con 'load_iris'.\n",
    "\n",
    "'data.data' (en la x), Contiene las características de longitud y ancho de sépalos y pétalos.\n",
    "\n",
    "'data.target' (en la y), tiene las etiquetas 0, 1, 2 que corresponden a especies de iris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe6457e-1c0f-4ad3-9283-009784f8b40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2808d498-f022-47c0-9255-36463501a160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset de Iris\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5620fa8-9c2d-456d-a100-8a2e935b16ee",
   "metadata": {},
   "source": [
    "### 2. Dividir el conjunto en entrenamiento y prueba\n",
    "\n",
    "Aqui estamos dividiendo los datos, el 80% va para entrenamiento y el 20% lo reservamos para las pruebas.\n",
    "\n",
    "Hemos usado 'stratify=y' para mantener la proporción de clases en ambos conjuntos.\n",
    "\n",
    "Luego, hemos usado 'random_state=42' para asegurar que los resultados sean reproducibles.\n",
    "\n",
    "Y para verificar la distribución de clases, se cuentan cuántos ejemplos hay de cada clase en el conjuno de entrenamiento para verificar que la división se ha hecho de forma balanceada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e233f15-b527-469a-8035-624ca69a30b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Verificar distribución de clases\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(\"Distribución de clases en el conjunto de entrenamiento:\", dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b1cfee-3c12-4061-9881-d04c4f236f12",
   "metadata": {},
   "source": [
    "### 3. Entrenamineto del Árbol de Decisión con ajuste de hiperparámetros\n",
    "\n",
    "Aquí definimos la profundidad del arbol (max_depth), y luego el número mínimo de muestras necesarias para dividir un nodo (min_samples_split).\n",
    "\n",
    "Para buscar la mejor combinación de hiperparámetros probando la con la validación cruzada (cv=5) hemos usado 'GridSearchCV'.\n",
    "\n",
    "Obtenemos el mejor modelo encontrado por 'GridSearchCV' y se usa para hacer las predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24365733-2180-4edd-affc-1d234e51c340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Modelo de Árbol de Decisión con ajuste de hiperparámetros\n",
    "param_grid_dt = {\"max_depth\": [3, 5, 10, None], \"min_samples_split\": [2, 5, 10]}\n",
    "grid_dt = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid_dt, cv=5)\n",
    "grid_dt.fit(X_train, y_train)\n",
    "\n",
    "dt_best = grid_dt.best_estimator_\n",
    "y_pred_dt = dt_best.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7449953-271a-44f4-91be-625ea2ccdfb4",
   "metadata": {},
   "source": [
    "### 4. Evaluación del Árbol de Decisión\n",
    "\n",
    "Se muestra los mejores hiperparámetros encontrados.\n",
    "\n",
    "Se calcula la precisión del modelo.\n",
    "\n",
    "Se muestra la matriz de confusión (compara las predicciones y los valores reales).\n",
    "\n",
    "Se genera un informe de clasificación con precisión, recall y F1-score para cada clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a84df21-d280-4d12-a92b-cbfb594b92d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMejor configuración para Árbol de Decisión:\", grid_dt.best_params_)\n",
    "print(\"\\nEvaluación del Árbol de Decisión:\")\n",
    "print(\"Precisión:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(\"Matriz de Confusión:\\n\", confusion_matrix(y_test, y_pred_dt))\n",
    "print(\"Informe de Clasificación:\\n\", classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3128fc5b-0d91-49c1-845c-2baa40ba39b5",
   "metadata": {},
   "source": [
    "### 5. Visualización del Árbol de Decisión\n",
    "\n",
    "Esto dibuja el arbol de decisión que hemos entrenado, mostrando los nodos y reglas de decisión.\n",
    "\n",
    "'feature_names=data.feature_names': Etiqueta las características (longitud y ancho de sépalos y pétalos).\n",
    "\n",
    "'class_names=data.target_names': Etiqueta las clases de iris.\n",
    "\n",
    "'filled=True': Colorea los nodos según la clase predominante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bbbf91-9ff3-4c6a-b796-e8396c5b3c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar el árbol\n",
    "plt.figure(figsize=(12, 6))\n",
    "plot_tree(dt_best, feature_names=data.feature_names, class_names=data.target_names, filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37670621-cd9e-4d06-aa6a-e4792a8d11c3",
   "metadata": {},
   "source": [
    "### 6. Entrenamiento del Bosque Aleatorio con ajuste de hiperparámetros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35a14af-7d47-4490-869b-cd9a0d149bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Modelo de Bosque Aleatorio con ajuste de hiperparámetros\n",
    "param_grid_rf = {\"n_estimators\": [50, 100, 200], \"max_depth\": [3, 5, 10, None], \"min_samples_split\": [2, 5, 10]}\n",
    "grid_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=5)\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "rf_best = grid_rf.best_estimator_\n",
    "y_pred_rf = rf_best.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b41dc5-5934-40c7-af5d-b86b6bbd6201",
   "metadata": {},
   "source": [
    "### 7. Evaluación del Bosque Aleatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f2207a-5220-4da8-9af1-79a8e9cf715c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMejor configuración para Random Forest:\", grid_rf.best_params_)\n",
    "print(\"\\nEvaluación del Bosque Aleatorio:\")\n",
    "print(\"Precisión:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Matriz de Confusión:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
    "print(\"Informe de Clasificación:\\n\", classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846ea607-5367-47ea-b9c4-ea661946f846",
   "metadata": {},
   "source": [
    "### 8. Análisis de la importancia de características en Random Forest\n",
    "\n",
    "'rf_best.feature_importances_': Obtiene la importancia de cada característica en la predicción.\n",
    "\n",
    "Se representa la importancia de cada característica con un gráfico de barras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b56963-291b-4a45-8798-e74d5076ee52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importancia de características\n",
    "feature_importances = rf_best.feature_importances_\n",
    "sns.barplot(x=feature_importances, y=data.feature_names)\n",
    "plt.xlabel(\"Importancia\")\n",
    "plt.ylabel(\"Características\")\n",
    "plt.title(\"Importancia de Características en Random Forest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65a1564-651e-4e06-8a25-a4d26d4305d1",
   "metadata": {},
   "source": [
    "### 9. Conclusiones\n",
    "\n",
    "1. Desempeño de los modelos\n",
    "\n",
    "El Bosque Aleatorio ha tenido una mejor precisión en comparación con el Árbol de Decisión, esto nos indica que la combinación de múltiples árboles mejora la capacidad de generalización del modelo.\n",
    "La matriz de confusión y el informe de clasificación nos muestra que el Bosque Aleatorio tiene menos errores de clasificación que el Árbol de Decisión.\n",
    "\n",
    "2. Importancia de las características\n",
    "\n",
    "El análisis de la importancia de las características en el Bosque Aleatorio nos revela qué variables influyen más en la predicción.\n",
    "En este caso, algunas de las características del dataset de Iris tienen mayor peso en la clasificación, esto permite entender mejor qué factores son clave en la toma de decisiones del modelo.\n",
    "\n",
    "3. Interpretable vs. Preciso\n",
    "\n",
    "El Árbol de Decisión es más fácil de interpretar y visualizar, esto es útil para entender el proceso de decisión del modelo.\n",
    "El Bosque Aleatorio, aunque es menos sencillo de interpretar, nos da mejores resultados en cuanto a precisión y robustez, porque reduce el sobreajuste al promediar múltiples árboles.\n",
    "\n",
    "4.Recomendaciones finales\n",
    "\n",
    "Si el objetivo es una interpretación clara de las decisiones del modelo, el Árbol de Decisión es una buena opción.\n",
    "Si se busca un mejor desempeño en términos de precisión y generalización, el Bosque Aleatorio es la mejor elección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a8d90f-49d2-4410-a928-3d7fc28fe1f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
