{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aa4e95a-224b-4bd4-9864-cde7c1297e14",
   "metadata": {},
   "source": [
    "# **Práctica 8: Clasificación con Validación Cruzada**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ba40c1-6603-4928-b1c6-11e9ea4d9d76",
   "metadata": {},
   "source": [
    "En este proyecto se va a aplicar tres modelos de Clasificación :\n",
    "- Árboles de Decisión\n",
    "- Regresión Logística\n",
    "- K-Nearest Neighbors\n",
    "  \n",
    "Para predecir si un tumor es maligno o benigno.\n",
    "\n",
    "\n",
    "Se utilizará validación cruzada para evaluar el rendimiento de cada modelo con diferentes valores de k (k=5 y k=10)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc82fce-67d8-4fbf-98ac-8ed928a6e6d5",
   "metadata": {},
   "source": [
    "## **Importamos Librerias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9528b4-e57c-46d9-b0f6-476632b176cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e358ae1-2557-446d-a37d-c52ae6518e73",
   "metadata": {},
   "source": [
    "## **Cargamos los Datos**\n",
    "Hacemos un análisis usando las estadisticas básicas y verificamos la estructura de los datos (numero de muestras, caracteristicas, etc)\n",
    "\n",
    "El dataset que tenemos sobre cancer tiene varias características y una columna que indica si el tumor es benigno o maligno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a25db1f-4751-449e-80be-f2bfc1746d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga del dataset y exploracion\n",
    "cancer = pd.read_csv(\"C:data.csv\")\n",
    "print(cancer)\n",
    "print(cancer.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5c06ca-13c9-4693-81b1-d5b7965a98ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# análisis estadístico con media, mediana, minimo, maximo. \n",
    "# rango intercuartílico (que nos ayuda a cuantificar una muestra eliminando los valores extremadamente alejados) \n",
    "# para valores atípicos y distribución de los datos \n",
    "print (cancer.describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2784bc26-12ea-4bb0-b4ab-218570be3d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos a hacer dos cambios\n",
    "# la columna 32 \"Unnamed: 32\" son todo valores nulos y vamos a eliminarla\n",
    "# vamos a detectar datos nulos\n",
    "cancer.isnull()\n",
    "cancer.drop(columns=[\"Unnamed: 32\",\"id\"], inplace = True)\n",
    "# el segundo cambio es de la columna 1 \"diagnosis\" cambiar el tipo abject de valores \"M\" para maligno y \"B\" para benigno \n",
    "# a 0 y 1\n",
    "cancer['diagnosis'] = cancer['diagnosis'].map({'M':1, 'B':0})\n",
    "print(cancer.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568b1d2e-1a4c-4586-ba8f-80e0775740cd",
   "metadata": {},
   "source": [
    "Hemos eliminado la columna \"id\" que no nos aportaba nada, la columna \"Unnamed: 32\" que eran todo valores nulos y, por último, hemos transformado los datos de la columna \"diagnosis\" porque no eran de tipo numerico y no nos servirian para entrenar al modelo correctamente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f73e542-d017-43f8-ad4c-2c022df40385",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cancer.duplicated().sum()) #duplicados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2061c9-18aa-42e2-8326-a8b07fe6e0ce",
   "metadata": {},
   "source": [
    "Ahora que ya estan limpios nuestros datos vamos a visualizarlos antes de entrenar a nuestro modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8235c570-177c-421d-96fd-45c9c1a0a3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos a ver que variables estan correlacionadas con la columna objetivo \n",
    "cancer.corr()['diagnosis'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89946c52-cdf1-4bb0-a84c-c45ab00a64bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ahora vamos a obtener las características con mayor varianza, que suelen tener informacion valiosa\n",
    "cancer.var().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92250163-5c77-49eb-9d30-0628a293201b",
   "metadata": {},
   "source": [
    "Los graficos con puntos de distintos colores bien separados indica que las variables de esa grafica podrian ser muy relevantes para el modelo.\n",
    "\n",
    "En cambio cuando vemos superposicion de colores, esas variables suelen tener poco valor predictivo po si solas.\n",
    "\n",
    "Como usar pairplot nos daba demasiados datos vamos a usar las variables con alta correlacion con la columna \"diagnosis\" y las variables con mayor varianza, que suelen tener mas informacion.\n",
    "\n",
    "criterios para seleccionar las variables:\n",
    "- correlacion >= 0.5 (muestra una fuerte relacion con el diagnostico)\n",
    "- varianza >= 1000 (evitara incluir variables con cambios insignificantes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691b1f91-29b7-4843-acdb-54795e76acaa",
   "metadata": {},
   "source": [
    "Variables con alta correlacion y buena varianza:\n",
    "- concave points_worst (corr = 0.79, var = 0.004)\n",
    "\n",
    "- perimeter_worst (corr = 0.78, var = 1129)\n",
    "\n",
    "- concave points_mean (corr = 0.77, var = 0.001)\n",
    "\n",
    "- radius_worst (corr = 0.77, var = 23)\n",
    "\n",
    "- perimeter_mean (corr = 0.74, var = 590)\n",
    "\n",
    "- area_worst (corr = 0.73, var = 324167)\n",
    "\n",
    "- radius_mean (corr = 0.73, var = 12)\n",
    "\n",
    "- area_mean (corr = 0.70, var = 123843)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0b4eda-0304-4fbd-b53b-d88154351f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usaremos un grafico que nos muestre como se relacionan estas variables con el objetivo \"diagnosis\"\n",
    "\n",
    "cols = [\n",
    "    'diagnosis', 'concave points_worst', 'perimeter_worst', 'concave points_mean', \n",
    "    'radius_worst', 'perimeter_mean', 'area_worst', 'radius_mean', 'area_mean'\n",
    "]\n",
    "sns.pairplot(cancer[cols], hue='diagnosis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39b93da-e7cd-4bee-b016-71c7ab022aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos a probar con un mapa de calor para detectar patrones\n",
    "plt.figure(figsize=(8,10))\n",
    "sns.heatmap(cancer[cols].corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Matriz de correlación')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d90520-3721-44ed-acf1-584804021e68",
   "metadata": {},
   "source": [
    "A continuación se muestran tres graficas con variables altamente correlacionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cade309-7dfe-41fa-a713-3778979f8c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=cancer, x='perimeter_worst', y='area_worst', hue='diagnosis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecdfd9d-b25c-4d35-8cc6-b93486c90959",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=cancer, x='perimeter_worst', y='radius_worst', hue='diagnosis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178d5a9a-9540-42db-a28b-ce17ca8dff6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=cancer, x='perimeter_mean', y='radius_mean', hue='diagnosis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6628512-1e05-4114-8e15-3e3f8bac6d59",
   "metadata": {},
   "source": [
    "## **División del Dataset**\n",
    "Se divide el conjunto de datos en entrenamiento (80%) y prueba (20%).\n",
    "\n",
    "Esto nos va a permitir evaluar el rendimiento real de los modelos con datos no vistos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f12547-27e2-461a-939b-717c9c2c8096",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cancer.drop('diagnosis', axis=1)\n",
    "y = cancer['diagnosis']\n",
    "\n",
    "# división inicial\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf38a9c0-9305-428b-9566-86fd8b33fb8f",
   "metadata": {},
   "source": [
    "## **Escalado de Datos**\n",
    "Como vamos a usar Regresión Logística y KNN, que son modelos sensibles a la escala de datos, es imprescindible normalizar los datos antes de usarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a827a707-7195-4a25-9aeb-01ff316ad16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test) # el conjunto de prueba se transforma usando el mismo scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dd3b83-e6ff-4a1f-bd6b-15dbb2ee1ad3",
   "metadata": {},
   "source": [
    "## **Validación Cruzada con K-Fold (k=5 y k=10)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9a057d-f2a4-4454-a525-942df2178f73",
   "metadata": {},
   "source": [
    "Cada modelo se evaluará usando 5-fold y 10-fold para comparar resultados.\n",
    "\n",
    "Aplicamos un modelo de Árbol de Decision usando validación cruzada k-fold con distintos valores de k (k=5, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3844d263-84dd-42ed-8fdd-ba3e876e799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo de arbol de decisión\n",
    "tree_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Validación cruzada con k=5\n",
    "scores_5 = cross_val_score(tree_model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Validación cruzada con  k=10\n",
    "scores_10 = cross_val_score(tree_model, X_train_scaled, y_train, cv=10, scoring='accuracy')\n",
    "\n",
    "print(f\"Precisión Árbol (k=5): {scores_5.mean():.4f}\")\n",
    "print(f\"Precisión Árbol (k=10): {scores_10.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf27413-6674-450a-9e67-a8482d38d78a",
   "metadata": {},
   "source": [
    "Aplicamos otros modelos: Regresión Logística y K-NN y repetir la Validación Cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a60c02-dca3-4d73-837f-6f5691a0f42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo de Regresión Logística\n",
    "logreg_model = LogisticRegression(max_iter=10000, random_state=42)\n",
    "\n",
    "scores_logreg_5 = cross_val_score(logreg_model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "scores_logreg_10 = cross_val_score(logreg_model, X_train_scaled, y_train, cv=10, scoring='accuracy')\n",
    "\n",
    "print(f\"Precisión Logística (k=5): {scores_logreg_5.mean():.4f}\")\n",
    "print(f\"Precisión Logística (k=10): {scores_logreg_10.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908a8d92-d8a6-4a9c-b397-f58fc12914ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo KNN con k=5\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "scores_knn_5 = cross_val_score(knn_model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "scores_knn_10 = cross_val_score(knn_model, X_train_scaled, y_train, cv=10, scoring='accuracy')\n",
    "\n",
    "print(f\"Precisión KNN (k=5): {scores_knn_5.mean():.4f}\")\n",
    "print(f\"Precisión KNN (k=10): {scores_knn_10.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfcba54-c2da-4992-9b07-1002e21ba447",
   "metadata": {},
   "source": [
    "## **Comparación de Resultados de la Validación Cruzada**\n",
    "\n",
    "Creamos un DataFrame con las precisiones medias para facilitar la visualización de los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8298c9c8-4e80-406c-883e-c9b04a1e14bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = pd.DataFrame({\n",
    "    'Modelo': ['Árbol de Decisión', 'Regresión Logística', 'KNN'],\n",
    "    'Precisión k=5': [scores_5.mean(), scores_logreg_5.mean(), scores_knn_5.mean()],\n",
    "    'Precisión k=10': [scores_10.mean(), scores_logreg_10.mean(), scores_knn_10.mean()]\n",
    "})\n",
    "\n",
    "print(resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6969e4e-86e4-403a-a099-7249a018eb72",
   "metadata": {},
   "source": [
    "## **Análisis del Impacto del Valor de K**\n",
    "\n",
    "Primero se va a mostrar los gráficos individuales para analizar el impacto de k y despues habrá un gráfico comparativo de los modelos que se han usado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0260734e-ba7e-47c1-b15c-c5cb0582eeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arbol de decision\n",
    "k_values = range(3, 16)  # Valores de k de 3 a 15\n",
    "tree_scores = [cross_val_score(tree_model, X_train_scaled, y_train, cv=k, scoring='accuracy').mean() for k in k_values]\n",
    "\n",
    "plt.plot(k_values, tree_scores, marker='o', label='Árbol de Decisión')\n",
    "plt.xlabel('Número de Folds (k)')\n",
    "plt.ylabel('Precisión Media')\n",
    "plt.title('Rendimiento del Árbol de Decisión')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0df7c7-bb0f-47ee-aa99-c17229317e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regresión Logística\n",
    "logreg_scores = [cross_val_score(logreg_model, X_train_scaled, y_train, cv=k, scoring='accuracy').mean() for k in k_values]\n",
    "\n",
    "plt.plot(k_values, logreg_scores, marker='o', label='Regresión Logística')\n",
    "plt.xlabel('Número de Folds (k)')\n",
    "plt.ylabel('Precisión Media')\n",
    "plt.title('Rendimiento de Regresión Logística')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14964cc1-08c2-4094-807a-712ada151262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "knn_scores = [cross_val_score(knn_model, X_train_scaled, y_train, cv=k, scoring='accuracy').mean() for k in k_values]\n",
    "\n",
    "plt.plot(k_values, knn_scores, marker='o', label='KNN')\n",
    "plt.xlabel('Número de Folds (k)')\n",
    "plt.ylabel('Precisión Media')\n",
    "plt.title('Rendimiento de KNN')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47bd659-a807-4414-b485-656174647492",
   "metadata": {},
   "source": [
    "## **Gráfico Comparativo de Modelos**\n",
    "\n",
    "Con esta gráfica vamos a poder comparar visualmente las precisiones alcanzadas por cada modelo con k=5 y k=10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7518da3b-7905-40f1-84d3-ef7fd5989113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gráfico comparativo\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "resultados_melted = resultados.melt(id_vars='Modelo', \n",
    "                                    value_vars=['Precisión k=5', 'Precisión k=10'],\n",
    "                                    var_name='k',\n",
    "                                    value_name='Precisión')\n",
    "\n",
    "\n",
    "sns.barplot(x='Modelo', y='Precisión', hue='k', data=resultados_melted)\n",
    "\n",
    "plt.title('Comparación de precisión entre modelos (k=5 vs k=10)')\n",
    "plt.ylabel('Precisión Media')\n",
    "plt.legend(title='Valor de k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b602c59a-18f4-4ef7-bbd7-465d0cf3c9c2",
   "metadata": {},
   "source": [
    "## **Conclusiones**\n",
    "\n",
    "- **Comparación entre Modelos :** El modelo de Regresión Logística ha mostrado un rendimiento más consistente en los dos valores de k que hemos probado, esto nos sugiere que este modelos puede generalizar mejor en este conjunto de datos. El modelo de Árbol de Decisión es el que ha variado más cuando cambiamos el valor de k. \n",
    "\n",
    "- **Impacto del Valor de K :** El uso de k=10 nos ha proporcionado resultados más estables que cuando hemos usado k=5, sobretodo en modelos como KNN y Árboles de Decisión. Esto es porqué un mayor número de folds reduce el sesgo pero incrementa la varianza en el entrenamiento.\n",
    "\n",
    "- **Modelo más Eficaz :** En este caso, la Regresión Logística ha sido la más precisa y estable, así que, esta sería la elección más adecuada para el caso de este conjunto de datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3a3400-2300-4df4-8bd0-275c1820ccdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
