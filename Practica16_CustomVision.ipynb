{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c866ffbc",
   "metadata": {},
   "source": [
    "## Práctica 16: Clasificación de imágenes con la API de Custom Vision (Microsoft Azure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb0df6b",
   "metadata": {},
   "source": [
    "### Objetivo de la práctica\n",
    "\n",
    "El objetivo de esta práctica es crear un modelo de **clasificación de imágenes** utilizando el servicio **Custom Vision** de Microsoft Azure, cubriendo todas las fases del proceso:\n",
    "\n",
    "- Creación y configuración del proyecto en la plataforma.\n",
    "- Carga de imágenes y etiquetado por clases.\n",
    "- Entrenamiento automático del modelo.\n",
    "- Evaluación con nuevas imágenes.\n",
    "- Inferencia mediante la **API REST** usando Python.\n",
    "- Visualización de los resultados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19323744",
   "metadata": {},
   "source": [
    "## 1. Preparación del entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4e7ec4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-cognitiveservices-vision-customvision in c:\\users\\andrea\\anaconda3\\lib\\site-packages (3.1.1)\n",
      "Requirement already satisfied: msrest>=0.6.21 in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from azure-cognitiveservices-vision-customvision) (0.7.1)\n",
      "Requirement already satisfied: azure-common~=1.1 in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from azure-cognitiveservices-vision-customvision) (1.1.28)\n",
      "Requirement already satisfied: azure-mgmt-core<2.0.0,>=1.2.0 in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from azure-cognitiveservices-vision-customvision) (1.5.0)\n",
      "Requirement already satisfied: azure-core>=1.31.0 in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from azure-mgmt-core<2.0.0,>=1.2.0->azure-cognitiveservices-vision-customvision) (1.33.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from msrest>=0.6.21->azure-cognitiveservices-vision-customvision) (2024.7.4)\n",
      "Requirement already satisfied: isodate>=0.6.0 in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from msrest>=0.6.21->azure-cognitiveservices-vision-customvision) (0.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from msrest>=0.6.21->azure-cognitiveservices-vision-customvision) (1.3.1)\n",
      "Requirement already satisfied: requests~=2.16 in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from msrest>=0.6.21->azure-cognitiveservices-vision-customvision) (2.32.2)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\andrea\\appdata\\roaming\\python\\python312\\site-packages (from azure-core>=1.31.0->azure-mgmt-core<2.0.0,>=1.2.0->azure-cognitiveservices-vision-customvision) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from azure-core>=1.31.0->azure-mgmt-core<2.0.0,>=1.2.0->azure-cognitiveservices-vision-customvision) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from requests~=2.16->msrest>=0.6.21->azure-cognitiveservices-vision-customvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from requests~=2.16->msrest>=0.6.21->azure-cognitiveservices-vision-customvision) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from requests~=2.16->msrest>=0.6.21->azure-cognitiveservices-vision-customvision) (2.2.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-cognitiveservices-vision-customvision) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install azure-cognitiveservices-vision-customvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dde5a5",
   "metadata": {},
   "source": [
    "## 2. Instalación de librerías y configuración de la API\n",
    "\n",
    "Importamos las librerías necesarias y configuramos la conexión con nuestro proyecto de Custom Vision. Es importante mantener seguras las claves API, evitando exponerlas en repositorios públicos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "010af5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "import os\n",
    "\n",
    "# Aquí vamos a usar mis datos\n",
    "ENDPOINT = \"https://westeurope.api.cognitive.microsoft.com\" # endpoint aqui\n",
    "PREDICTION_KEY = \"60c15c78ac234257bace0c5a38103bb2\"  # prediction key aqui\n",
    "PROJECT_ID = \"42fdc420-14c8-4a46-9410-8c8ec835bef5\"  # project ID aqui\n",
    "PUBLISH_ITERATION_NAME = \"Iteration1\" # no le he cambiado el nombre\n",
    "\n",
    "# Autenticacion\n",
    "prediction_credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": PREDICTION_KEY})\n",
    "predictor = CustomVisionPredictionClient(ENDPOINT, prediction_credentials)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fa851e",
   "metadata": {},
   "source": [
    "## 3. Clasificación de nuevas imágenes\n",
    "\n",
    "Para comprobar el rendimiento del modelo, utilizamos imágenes que **no se usaron en el entrenamiento**. Estas se procesan desde una carpeta local y se clasifican mediante la API de predicción.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d590131d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados para imagen: 1.png\n",
      "\n",
      "Ardilla: 99.99% de confianza\n",
      "\n",
      "Loro: 0.01% de confianza\n",
      "\n",
      "Tortuga: 0.00% de confianza\n",
      "\n",
      "Resultados para imagen: 2.png\n",
      "\n",
      "Ardilla: 88.23% de confianza\n",
      "\n",
      "Loro: 11.77% de confianza\n",
      "\n",
      "Tortuga: 0.00% de confianza\n",
      "\n",
      "Resultados para imagen: 3.png\n",
      "\n",
      "Ardilla: 100.00% de confianza\n",
      "\n",
      "Loro: 0.00% de confianza\n",
      "\n",
      "Tortuga: 0.00% de confianza\n",
      "\n",
      "Resultados para imagen: 4.png\n",
      "\n",
      "Tortuga: 99.94% de confianza\n",
      "\n",
      "Loro: 0.06% de confianza\n",
      "\n",
      "Ardilla: 0.00% de confianza\n",
      "\n",
      "Resultados para imagen: 5.png\n",
      "\n",
      "Tortuga: 99.94% de confianza\n",
      "\n",
      "Loro: 0.06% de confianza\n",
      "\n",
      "Ardilla: 0.00% de confianza\n",
      "\n",
      "Resultados para imagen: 6.png\n",
      "\n",
      "Tortuga: 99.67% de confianza\n",
      "\n",
      "Loro: 0.31% de confianza\n",
      "\n",
      "Ardilla: 0.02% de confianza\n",
      "\n",
      "Resultados para imagen: 7.png\n",
      "\n",
      "Loro: 100.00% de confianza\n",
      "\n",
      "Ardilla: 0.00% de confianza\n",
      "\n",
      "Tortuga: 0.00% de confianza\n",
      "\n",
      "Resultados para imagen: 8.png\n",
      "\n",
      "Loro: 100.00% de confianza\n",
      "\n",
      "Tortuga: 0.00% de confianza\n",
      "\n",
      "Ardilla: 0.00% de confianza\n",
      "\n",
      "Resultados para imagen: 9.png\n",
      "\n",
      "Loro: 100.00% de confianza\n",
      "\n",
      "Ardilla: 0.00% de confianza\n",
      "\n",
      "Tortuga: 0.00% de confianza\n"
     ]
    }
   ],
   "source": [
    "# Carpeta con imagenes para probar\n",
    "test_images_folder =  \"./test\"  # Cabiar si cambia la ruta de la carpeta\n",
    "\n",
    "# Leer y clasificar cada imagen\n",
    "for image_file in os.listdir(test_images_folder):\n",
    "    if image_file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "        image_path = os.path.join(test_images_folder, image_file)\n",
    "        with open(image_path, \"rb\") as image_data:\n",
    "            results = predictor.classify_image(\n",
    "                PROJECT_ID, PUBLISH_ITERATION_NAME, image_data.read()\n",
    "            )\n",
    "            \n",
    "            # Mostrar resultados\n",
    "            print(f\"\\nResultados para imagen: {image_file}\")\n",
    "            for prediction in results.predictions:\n",
    "                print(f\"\\n{prediction.tag_name}: {prediction.probability * 100:.2f}% de confianza\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3424ac0d",
   "metadata": {},
   "source": [
    "## 4. Resultados de las predicciones\n",
    "\n",
    "El modelo demostró un rendimiento muy sólido, diferenciando correctamente entre clases como **Ardilla**, **Tortuga** y **Loro**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d7eeaa-b6e6-428a-aa8c-cdca3d2aab87",
   "metadata": {},
   "source": [
    "## 5. Evaluación en la plataforma Custom Vision\n",
    "\n",
    "### Vista general del proyecto : Preparación del dataset en Custom Vision\n",
    "\n",
    "En la plataforma Azure Custom Vision, se creó un nuevo proyecto de clasificación multicategoría. Se subieron un total de 90 imágenes, divididas en tres clases: ardilla (30 imágenes), tortuga (30 imágenes) y loro (30 imágenes).\n",
    "Cada imagen fue etiquetada manualmente con su categoría correspondiente, asegurando que el conjunto de datos estuviera equilibrado en número de ejemplos por clase. Este paso es crucial para evitar que el modelo se sesgue hacia una clase en particular.\n",
    "\n",
    "La plataforma permite visualizar rápidamente el número de imágenes por clase, facilitando el control de calidad del dataset antes del entrenamiento.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"imagenes_customvision/proyecto_customvision.png\" width=\"1000\"/>\n",
    "</p>\n",
    "\n",
    "Aquí se muestra la interfaz del proyecto en Custom Vision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2306e5d6-f508-4973-b343-7de62f17b84e",
   "metadata": {},
   "source": [
    "### Resultados del entrenamiento del modelo : Entrenamiento del modelo en Custom Vision\n",
    "\n",
    "Una vez preparado el conjunto de datos, se inició el entrenamiento automático del modelo seleccionando el tipo de clasificación con una sola etiqueta por imagen. El modelo fue entrenado utilizando los algoritmos internos de Custom Vision, que dividen automáticamente las imágenes en subconjuntos de entrenamiento y validación (80/20).\n",
    "\n",
    "Al finalizar el entrenamiento, la plataforma mostró métricas clave para evaluar el rendimiento del modelo:\n",
    "\n",
    "Precisión (Precision): Proporción de predicciones correctas entre las imágenes que el modelo identificó como una clase determinada.\n",
    "\n",
    "Recall: Proporción de imágenes correctamente identificadas entre todas las imágenes reales de esa clase.\n",
    "\n",
    "Average Precision (AP): Métrica que resume el área bajo la curva precisión-recall, útil para evaluar el rendimiento general del modelo.\n",
    "\n",
    "Los resultados obtenidos mostraron un buen equilibrio entre precisión y recall en las tres clases, lo cual indica que el modelo es capaz de distinguir correctamente entre las imágenes de ardillas, tortugas y loros.\n",
    " \n",
    "<p align=\"center\">\n",
    "  <img src=\"imagenes_customvision/entrenamiento.png\" width=\"700\"/>\n",
    "</p>\n",
    "\n",
    "El modelo obtuvo una precisión del 100%, un resultado muy elevado que probablemente se debe a que las imágenes utilizadas son visualmente simples y bien diferenciadas. Si se hubieran utilizado imágenes más complejas —por ejemplo, con variaciones de ángulo, color o iluminación—, es probable que la precisión hubiera disminuido. Sin embargo, esto habría dado lugar a un modelo más robusto y realista, con mejor capacidad de generalización ante situaciones del mundo real.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b713817a-2f3a-480d-b2b3-28132a819133",
   "metadata": {},
   "source": [
    "### Predicción rápida (Quick Test) : Resultados del Quick Test en Custom Vision\n",
    "\n",
    "Para validar el comportamiento del modelo, se utilizó la funcionalidad de Quick Test en la plataforma, subiendo un total de 9 imágenes nuevas (3 por clase) que no habían sido utilizadas durante el entrenamiento.\n",
    "\n",
    "Cada imagen fue evaluada de forma individual y el modelo devolvió:\n",
    "\n",
    "La clase predicha.\n",
    "\n",
    "La probabilidad asociada a esa predicción.\n",
    "\n",
    "En algunos casos, un porcentaje de confianza bajo si la imagen era ambigua o poco clara, lo cual es un indicador útil sobre la incertidumbre del modelo.\n",
    "\n",
    "En general, el modelo identificó correctamente la mayoría de las imágenes, mostrando una buena capacidad de generalización. En las pocas imágenes donde hubo duda, el modelo aún fue capaz de identificar la clase más probable con una puntuación aceptable.\n",
    "\n",
    "A continuación se muestran las 9 imágenes utilizadas en la prueba rápida del modelo entrenado en Custom Vision.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"imagenes_customvision/quick_test_1.png\" width=\"350\"/>\n",
    "  <img src=\"imagenes_customvision/quick_test_2.png\" width=\"350\"/>\n",
    "</p>\n",
    "<p align=\"center\">\n",
    "  <img src=\"imagenes_customvision/quick_test_3.png\" width=\"350\"/>\n",
    "  <img src=\"imagenes_customvision/quick_test_4.png\" width=\"350\"/>\n",
    "</p>\n",
    "<p align=\"center\">\n",
    "  <img src=\"imagenes_customvision/quick_test_5.png\" width=\"350\"/>\n",
    "  <img src=\"imagenes_customvision/quick_test_6.png\" width=\"350\"/>\n",
    "</p>\n",
    "<p align=\"center\">\n",
    "  <img src=\"imagenes_customvision/quick_test_7.png\" width=\"350\"/>\n",
    "  <img src=\"imagenes_customvision/quick_test_8.png\" width=\"350\"/>\n",
    "</p>\n",
    "<p align=\"center\">\n",
    "  <img src=\"imagenes_customvision/quick_test_9.png\" width=\"350\"/>\n",
    "</p>\n",
    "\n",
    "\n",
    "En esta prueba rápida, el modelo identificó correctamente el contenido de las imágenes subidas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944a0138",
   "metadata": {},
   "source": [
    "## 6. Conclusiones\n",
    "\n",
    "✅ El modelo fue entrenado con éxito usando Custom Vision en Azure.  \n",
    "✅ Se logró una alta precisión en la clasificación de imágenes no vistas.  \n",
    "✅ La integración mediante la API REST es sencilla y efectiva para despliegue real.\n",
    "\n",
    "La plataforma Custom Vision de Microsoft Azure ha demostrado ser una herramienta accesible y potente para el desarrollo rápido de modelos de clasificación de imágenes. Su interfaz intuitiva permite cargar y etiquetar imágenes de forma sencilla, facilitando así el entrenamiento de modelos sin necesidad de conocimientos avanzados de machine learning.\n",
    "\n",
    "En este proyecto, se ha entrenado un modelo con 90 imágenes organizadas en tres clases (ardilla, tortuga y loro), obteniendo una precisión del 100%. Aunque este resultado es excelente en términos numéricos, es importante destacar que se ha logrado en un entorno controlado con imágenes sencillas y sin ruido. Para aplicaciones más realistas, se recomienda aumentar la complejidad del conjunto de datos y aplicar técnicas de aumento de datos para mejorar la capacidad del modelo de generalizar.\n",
    "\n",
    "La opción de Quick Test ha permitido validar rápidamente el rendimiento del modelo frente a nuevas imágenes, demostrando una correcta clasificación en los tres casos. No obstante, para una evaluación más rigurosa se debería utilizar un conjunto de prueba independiente y más diverso.\n",
    "\n",
    "Finalmente, el uso del script en Python para conectarse al modelo publicado, enviar imágenes y recibir predicciones ha sido fundamental para validar el despliegue del modelo de manera programática. Esta integración permite automatizar procesos, escalar el uso del modelo en aplicaciones reales y comprender el flujo completo desde la creación hasta el consumo del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ed46cd-92a8-4392-8099-44fa37414a61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
